ğŸ“Š ML Feature Engineering Pipeline (PySpark)
ğŸ“Œ Overview

This project focuses on feature engineering using PySpark to generate structured, machine-learningâ€“ready datasets from transactional data.
The pipeline aggregates raw spending data into monthly category-level features, which can be directly used for analytics, forecasting, or ML models.

The processed features are stored in a Gold layer table, following a Medallion (Bronzeâ€“Silverâ€“Gold) architecture.

ğŸ§  Key Features

Extracts year and month from transaction dates

Aggregates monthly spend per category

Generates clean ML-ready features

Writes output to a Gold table for downstream ML tasks

Built using PySpark DataFrame API

ğŸ—‚ï¸ Project Structure
.
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ feature_engineering.ipynb
â”‚   â””â”€â”€ exploratory_analysis.ipynb
â”œâ”€â”€ README.md

ğŸ”§ Tech Stack

Apache Spark (PySpark)

Python

Spark SQL

Databricks / Spark-compatible environment

ğŸ“ Feature Engineering Logic

The following features are created:

year â€“ extracted from transaction date

month â€“ extracted from transaction date

category â€“ spending category

monthly_category_spend â€“ total spend per category per month

These features are aggregated and stored in a Gold table:

your_catalog.your_schema.gold_ml_features

ğŸš€ How to Run

Set up a Spark / Databricks environment

Load the Silver-layer DataFrame (silver_df)

Run the notebook inside the notebooks/ folder

Verify the Gold table using Spark SQL

Example aggregation logic:

ml_features = (
    silver_df
    .withColumn("year", year("date"))
    .withColumn("month", month("date"))
    .groupBy("year", "month", "category")
    .agg(sum("amount").alias("monthly_category_spend"))
)

ml_features.write.mode("overwrite").saveAsTable(
    "your_catalog.your_schema.gold_ml_features"
)

ğŸ“ˆ Use Cases

Monthly spending trend analysis

Budget forecasting

Category-level ML models

Financial analytics dashboards

ğŸ§© Future Improvements

Add more time-based features (quarter, rolling averages)

Integrate ML models (forecasting / anomaly detection)

Add unit tests for feature validation

Automate pipeline using workflows
